{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ANe80oZgE79"
      },
      "source": [
        "## VeggedIn\n",
        "## - Abhishek Nair\n",
        "## - priyanshi Furiya\n",
        "## Problem Statement 5 - DataBytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D5mvVdXISax"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QabNNMJvV3Pq"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R2Bup4LWxhM",
        "outputId": "7fdc75e3-802a-4f7d-a9c8-3b168bd2b47a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading vegetable-image-dataset.zip to /content\n",
            " 98% 523M/534M [00:05<00:00, 122MB/s]\n",
            "100% 534M/534M [00:05<00:00, 102MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d misrakahmed/vegetable-image-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORLZCGoqWzwA",
        "outputId": "0609322d-404b-4718-cd7b-110f8f6a9125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-2.1.1-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-2.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install patool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tFhemolXDP9",
        "outputId": "0b00503c-6db0-429c-f28c-570414eab41b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO patool: Extracting /content/vegetable-image-dataset.zip ...\n",
            "INFO:patool:Extracting /content/vegetable-image-dataset.zip ...\n",
            "INFO patool: running /usr/bin/7z x -o./Unpack_oa5agfcs -- /content/vegetable-image-dataset.zip\n",
            "INFO:patool:running /usr/bin/7z x -o./Unpack_oa5agfcs -- /content/vegetable-image-dataset.zip\n",
            "INFO patool:     with input=''\n",
            "INFO:patool:    with input=''\n"
          ]
        }
      ],
      "source": [
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/vegetable-image-dataset.zip\")\n",
        "!rm /content/vegetable-image-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wj7iJWWVKJJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os, shutil\n",
        "from PIL import Image\n",
        "from PIL import ImageEnhance\n",
        "from skimage.io import imread\n",
        "import random, pathlib, warnings, itertools, math, os, shutil\n",
        "from tensorflow.keras import layers\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whBEYtSRIZiG"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SwF4ZEYV04B"
      },
      "outputs": [],
      "source": [
        "dataset= \"/content/Vegetable Images\"\n",
        "\n",
        "train_folder = os.path.join(dataset,\"train\")\n",
        "test_folder = os.path.join(dataset,\"validation\")\n",
        "validation_folder = os.path.join(dataset,\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trYQ1mwMQsW_"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkQqFyObTc6E"
      },
      "outputs": [],
      "source": [
        "train_data_generator = ImageDataGenerator(\n",
        "    rescale=1/255.,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=10\n",
        ")\n",
        "\n",
        "val_data_generator = ImageDataGenerator(\n",
        "    rescale=1/255.,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "test_data_generator = ImageDataGenerator(rescale=1/255.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9ZvFbGSLsLr",
        "outputId": "615923b0-6b30-4f4e-e46d-c28d584a9298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 15000 images belonging to 15 classes.\n",
            "Found 3000 images belonging to 15 classes.\n",
            "Found 3000 images belonging to 15 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_data_generator.flow_from_directory(\n",
        "    train_folder,\n",
        "    shuffle=True,\n",
        "    class_mode='binary',\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "val_generator = val_data_generator.flow_from_directory(\n",
        "    validation_folder,\n",
        "    shuffle=False,\n",
        "    class_mode='binary',\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "test_generator = test_data_generator.flow_from_directory(\n",
        "    test_folder,\n",
        "    shuffle=False,\n",
        "    class_mode='binary',\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BfVY156Iy50",
        "outputId": "7142a141-9692-4100-a788-eec681872d95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'Bean',\n",
              " 1: 'Bitter_Gourd',\n",
              " 2: 'Bottle_Gourd',\n",
              " 3: 'Brinjal',\n",
              " 4: 'Broccoli',\n",
              " 5: 'Cabbage',\n",
              " 6: 'Capsicum',\n",
              " 7: 'Carrot',\n",
              " 8: 'Cauliflower',\n",
              " 9: 'Cucumber',\n",
              " 10: 'Papaya',\n",
              " 11: 'Potato',\n",
              " 12: 'Pumpkin',\n",
              " 13: 'Radish',\n",
              " 14: 'Tomato'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_class_indices = train_generator.class_indices\n",
        "class_map = {v: k for k, v in train_class_indices.items()}\n",
        "class_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EULNXKNoQu-n",
        "outputId": "e04a46c5-6a42-423d-d9db-c8d6c7e60a2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "pretrained = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "    input_shape=[256,256,3], include_top=False,\n",
        "    classifier_activation='softmax',\n",
        ")\n",
        "pretrained.trainable = False\n",
        "model = tf.keras.models.Sequential([\n",
        "    pretrained,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(15, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYHgUn-BbSqH",
        "outputId": "8c8d8d45-3f78-45ec-e77a-a840e9ece725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Func  (None, 8, 8, 1280)        2257984   \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 1280)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               655872    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 15)                975       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2947663 (11.24 MB)\n",
            "Trainable params: 689679 (2.63 MB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfpO-FijREod"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\"model.h5\", save_best_only=True)\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping( monitor=\"val_loss\",patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tJPH6OnBorI"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4qM3o5qRIw8",
        "outputId": "1f01f4d7-3fa5-4657-9c71-b45e0a6dcbfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "469/469 [==============================] - 320s 668ms/step - loss: 0.1177 - accuracy: 0.9675 - val_loss: 0.0274 - val_accuracy: 0.9910\n",
            "Epoch 2/15\n",
            "469/469 [==============================] - 274s 585ms/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.0423 - val_accuracy: 0.9877\n",
            "Epoch 3/15\n",
            "469/469 [==============================] - 272s 580ms/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.1042 - val_accuracy: 0.9730\n",
            "Epoch 4/15\n",
            "469/469 [==============================] - 273s 582ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.0328 - val_accuracy: 0.9920\n",
            "Epoch 5/15\n",
            "469/469 [==============================] - 311s 663ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0138 - val_accuracy: 0.9947\n",
            "Epoch 6/15\n",
            "469/469 [==============================] - 278s 593ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0093 - val_accuracy: 0.9970\n",
            "Epoch 7/15\n",
            "469/469 [==============================] - 275s 586ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.0231 - val_accuracy: 0.9917\n",
            "Epoch 8/15\n",
            "469/469 [==============================] - 273s 582ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.0231 - val_accuracy: 0.9913\n",
            "Epoch 9/15\n",
            "469/469 [==============================] - 270s 575ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0068 - val_accuracy: 0.9973\n",
            "Epoch 10/15\n",
            "469/469 [==============================] - 272s 580ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0156 - val_accuracy: 0.9960\n",
            "Epoch 11/15\n",
            "469/469 [==============================] - 272s 580ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0190 - val_accuracy: 0.9947\n",
            "Epoch 12/15\n",
            "469/469 [==============================] - 272s 580ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0081 - val_accuracy: 0.9970\n",
            "Epoch 13/15\n",
            "469/469 [==============================] - 271s 579ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0169 - val_accuracy: 0.9960\n",
            "Epoch 14/15\n",
            "469/469 [==============================] - 271s 579ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.0287 - val_accuracy: 0.9923\n"
          ]
        }
      ],
      "source": [
        "epochs = 15\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data=val_generator,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[checkpoint_callback,early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJWwQiPkck2p"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('/content/final_model.h5')\n",
        "# predicted_vegetable = generate_predictions(\"/content/batata.jpg\")\n",
        "# print(predicted_vegetable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZFfapYxW-ap"
      },
      "outputs": [],
      "source": [
        "def generate_predictions(image_path):\n",
        "    test_img = image.load_img(image_path, target_size=(256, 256))\n",
        "    test_img_arr = image.img_to_array(test_img)/255.0\n",
        "    test_img_input = test_img_arr.reshape((1, test_img_arr.shape[0], test_img_arr.shape[1], test_img_arr.shape[2]))\n",
        "\n",
        "    predicted_label = np.argmax(model.predict(test_img_input))\n",
        "    predicted_vegetable = class_map[predicted_label]\n",
        "    return predicted_vegetable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "SpdKckpcXJLq",
        "outputId": "f11226bc-03b7-4d87-c2ca-7d5cb4ed0eb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Potato'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_predictions(\"/content/batata.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erl3sEOjLOeL"
      },
      "source": [
        "### Quantity (Object Detection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fF-VBHOGLYGT",
        "outputId": "ee4dd8ab-ada3-4bad-a16c-aa5a8c8c2d59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.19-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.18.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.47.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (0.7.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n",
            "Installing collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.9.0.80\n",
            "    Uninstalling opencv-python-headless-4.9.0.80:\n",
            "      Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.11.17\n",
            "    Uninstalling certifi-2023.11.17:\n",
            "      Successfully uninstalled certifi-2023.11.17\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.19 supervision-0.18.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cycler",
                  "idna"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gBXoItTVT_k"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtXHqMNHLONq",
        "outputId": "39cc2aa5-9516-427f-cdc0-f9a7092a454b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "#replace (userdata.get('RoboFlowAPI') with oTFdgfpUXCaDBg8v2Is6 if not working\n",
        "# rf = Roboflow(api_key=(userdata.get('RoboFlowAPI')))\n",
        "rf = Roboflow(api_key=\"oTFdgfpUXCaDBg8v2Is6\")\n",
        "project = rf.workspace().project(\"test-veg\")\n",
        "ModelCount = project.version(1).model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e2cOUIfSnwG"
      },
      "outputs": [],
      "source": [
        "def count_instances(predictions: dict) -> dict:\n",
        "    classes = {}\n",
        "\n",
        "    for bounding_box in predictions['predictions']:\n",
        "        if bounding_box['class'] in classes:\n",
        "            classes[bounding_box['class']] += 1\n",
        "        else:\n",
        "            classes[bounding_box['class']] = 1\n",
        "\n",
        "    return classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8gw8pXzS0R1"
      },
      "outputs": [],
      "source": [
        "prediction = ModelCount.predict(\"/content/images.jpeg\", confidence=40, overlap=30).save(\"prediction.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJvNe6TeNBHp"
      },
      "outputs": [],
      "source": [
        "count_instances(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MotLYkgfSRUF"
      },
      "source": [
        "### Calculating average weight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN58ol-cSVmN"
      },
      "outputs": [],
      "source": [
        "def calculate_weight_for_predicted_vegetable(\n",
        "    predicted_vegetable, quantity_dict, csv_file_path\n",
        "):\n",
        "    df = pd.read_csv(csv_file_path, encoding=\"latin1\")\n",
        "\n",
        "    df[\"Product\"] = df[\"Product\"].str.lower()\n",
        "\n",
        "    product_to_weight = dict(zip(df[\"Product\"], df[\"Weight\"]))\n",
        "\n",
        "    predicted_vegetable_lower = predicted_vegetable.lower()\n",
        "\n",
        "    if predicted_vegetable_lower not in quantity_dict:\n",
        "        print(\"Error Predicting Vegetable: Predicted vegetable not found in quantity_dict.\")\n",
        "        return None\n",
        "\n",
        "    if predicted_vegetable_lower in product_to_weight:\n",
        "        predicted_quantity = quantity_dict.get(predicted_vegetable_lower, 0)\n",
        "        total_weight = predicted_quantity * product_to_weight[predicted_vegetable_lower]\n",
        "        return total_weight\n",
        "    else:\n",
        "        print(\n",
        "            f\"Warning: Predicted vegetable '{predicted_vegetable}' not found in the CSV file.\"\n",
        "        )\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqrYnUlIWmUz"
      },
      "source": [
        "### Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5Ctd58yWlwr"
      },
      "outputs": [],
      "source": [
        "def generate_predictions_with_count(image_path):\n",
        "    predicted_vegetable = generate_predictions(image_path)\n",
        "    prediction = ModelCount.predict(image_path, confidence=40, overlap=30).json()\n",
        "    count = count_instances(prediction)\n",
        "    return predicted_vegetable, count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4Aa89irXNe8"
      },
      "outputs": [],
      "source": [
        "csv_path = \"/content/WeightMapping.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBuMYfCBlZNo"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "quantity_dict = {\n",
        "    'bean': 0, 'bitter_gourd': 0, 'bottle_gourd': 0, 'brinjal': 0,\n",
        "    'broccoli': 0, 'cabbage': 0, 'capsicum': 0, 'carrot': 0,\n",
        "    'cauliflower': 0, 'cucumber': 0, 'papaya': 0, 'potato': 0,\n",
        "    'pumpkin': 0, 'radish': 0, 'tomato': 0\n",
        "}\n",
        "\n",
        "list_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter the list of vegetables and quantities (e.g., bean:3,carrot:2,tomato:4)',\n",
        "    description='Vegetable List:'\n",
        ")\n",
        "\n",
        "submit_button = widgets.Button(description='Submit')\n",
        "display(widgets.HBox([list_input, submit_button]))\n",
        "image_path_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter the path to the image',\n",
        "    description='Image Path:'\n",
        ")\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_submit_click(b):\n",
        "    global items\n",
        "    items = None\n",
        "    try:\n",
        "        user_input = list_input.value\n",
        "        items = [item.split(':') for item in user_input.split(',')]\n",
        "        for vegetable, quantity in items:\n",
        "            quantity_dict[vegetable.strip().lower()] += int(quantity)\n",
        "        with output:\n",
        "            output.clear_output()\n",
        "            print(f\"Updated Purchase List: {quantity_dict}\")\n",
        "\n",
        "        display(image_path_input)\n",
        "\n",
        "    except ValueError:\n",
        "        with output:\n",
        "            output.clear_output()\n",
        "            print(\"Error: Invalid input format. Please enter quantities as integers.\")\n",
        "\n",
        "submit_button.on_click(on_submit_click)\n",
        "\n",
        "final_output = widgets.Output()\n",
        "display(final_output)\n",
        "\n",
        "def on_image_path_submit(b):\n",
        "    global items, quantity_dict\n",
        "    image_path = image_path_input.value\n",
        "    predicted_vegetable, count_dict = generate_predictions_with_count(image_path)\n",
        "    for vegetable, count in count_dict.items():\n",
        "        vegetable_lower = vegetable.lower()\n",
        "        if vegetable_lower in quantity_dict:\n",
        "            subtracted_count = min(count, quantity_dict[vegetable_lower])\n",
        "            quantity_dict[vegetable_lower] -= subtracted_count\n",
        "\n",
        "    predicted_vegetable_weight = calculate_weight_for_predicted_vegetable(\n",
        "        predicted_vegetable, count_dict, csv_path\n",
        "    )\n",
        "\n",
        "    with final_output:\n",
        "        final_output.clear_output()\n",
        "        if predicted_vegetable_weight is not None:\n",
        "            print(f\"Predicted Vegetable: {predicted_vegetable}\")\n",
        "            print(f\"Updated Purchase List: {quantity_dict}\")\n",
        "            print(f\"Total Weight: {predicted_vegetable_weight} grams\")\n",
        "        else:\n",
        "            print(\"Error calculating weight.\")\n",
        "\n",
        "\n",
        "image_path_submit_button = widgets.Button(description='Submit Image Path')\n",
        "image_path_submit_button.on_click(on_image_path_submit)\n",
        "display(image_path_submit_button)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07CYZTzrd3yV"
      },
      "source": [
        "### FrontEnd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Dn89XmDcWvh_",
        "outputId": "1a9c4cb7-7a1b-4f5c-a5b9-ac6012ed0489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.4.2-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/90.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m81.9/90.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting argparse (from anvil-uplink)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.16.0)\n",
            "Collecting ws4py (from anvil-uplink)\n",
            "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45228 sha256=284873e85ff7e6880ce8dad214bb76b8d5f24284d73a01036323d0a675789b66\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/7c/ad/d9c746276bf024d44296340869fcb169f1e5d80fb147351a57\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.4.2 argparse-1.4.0 ws4py-0.5.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install anvil-uplink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE4QSScaW7nf",
        "outputId": "3f8fd876-2862-4ff3-adbb-96eeb6a0ad27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default Environment\" as SERVER\n"
          ]
        }
      ],
      "source": [
        "import anvil.server\n",
        "\n",
        "anvil.server.connect(\"server_P6DBK2FAFASD7YJURYWZIDXK-PQARQF3OUZ6246MT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4dsDjv2Z9uN"
      },
      "outputs": [],
      "source": [
        "quantity_dict = {\n",
        "    'bean': 0, 'bitter_gourd': 0, 'bottle_gourd': 0, 'brinjal': 0,\n",
        "    'broccoli': 0, 'cabbage': 0, 'capsicum': 0, 'carrot': 0,\n",
        "    'cauliflower': 0, 'cucumber': 0, 'papaya': 0, 'potato': 0,\n",
        "    'pumpkin': 0, 'radish': 0, 'tomato': 0\n",
        "}\n",
        "\n",
        "@anvil.server.callable\n",
        "def process_input(vegetable, quantity):\n",
        "    global quantity_dict\n",
        "\n",
        "    try:\n",
        "        if vegetable.strip().lower() == 'reset':\n",
        "            quantity_dict = {\n",
        "                'bean': 0, 'bitter_gourd': 0, 'bottle_gourd': 0, 'brinjal': 0,\n",
        "                'broccoli': 0, 'cabbage': 0, 'capsicum': 0, 'carrot': 0,\n",
        "                'cauliflower': 0, 'cucumber': 0, 'papaya': 0, 'potato': 0,\n",
        "                'pumpkin': 0, 'radish': 0, 'tomato': 0\n",
        "            }\n",
        "            return {\"reset\": True, \"updated_vegetables\": {}}\n",
        "        else:\n",
        "            vegetable_lower = vegetable.strip().lower()\n",
        "            if vegetable_lower in quantity_dict:\n",
        "                quantity_dict[vegetable_lower] += int(quantity)\n",
        "                updated_vegetables = {vegetable_lower: quantity_dict[vegetable_lower]}\n",
        "                return {\"reset\": False, \"updated_vegetables\": updated_vegetables}\n",
        "            else:\n",
        "                return {\"error\": f\"Invalid vegetable: {vegetable}\"}\n",
        "\n",
        "    except ValueError:\n",
        "        return {\"error\": \"Invalid input format. Please enter quantities as integers.\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3YqMv4YaCbk"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def enter_image_path(image_path):\n",
        "    global quantity_dict\n",
        "\n",
        "    try:\n",
        "        predicted_vegetable, count_dict = generate_predictions_with_count(image_path)\n",
        "        for vegetable, count in count_dict.items():\n",
        "            vegetable_lower = vegetable.lower()\n",
        "            if vegetable_lower in quantity_dict:\n",
        "                subtracted_count = min(count, quantity_dict[vegetable_lower])\n",
        "                quantity_dict[vegetable_lower] -= subtracted_count\n",
        "        predicted_vegetable_weight = calculate_weight_for_predicted_vegetable(\n",
        "            predicted_vegetable, count_dict, csv_path\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"predicted_vegetable\": predicted_vegetable,\n",
        "            \"updated_purchase_list\": quantity_dict,\n",
        "            \"total_weight\": predicted_vegetable_weight\n",
        "        }\n",
        "\n",
        "    except ValueError:\n",
        "        return {\"error\": \"Error processing image path.\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPzsZbMnpvJy"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def get_shopping_list():\n",
        "    global quantity_dict\n",
        "    return quantity_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKhFPBRnXI4W",
        "outputId": "78e41b38-aa7c-46be-f7ed-cf33e5a4c285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n"
          ]
        }
      ],
      "source": [
        "anvil.server.wait_forever()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}